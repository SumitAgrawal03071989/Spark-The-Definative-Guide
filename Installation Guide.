PySpark with Jupyter notebook + Spark UI.

1. Install Spark with pip 

```
pip install pyspark
```

2. add env variables as below.

```
export SPARK_HOME=/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark
export PATH=$SPARK_HOME/bin:$PATH

export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port=8889'
```

in jupyter notebook run below command to check the SparkUI URL and

```
sc.uiWebUrl
```




Installation Guide.

Download spark-2.4.5 from https://spark.apache.org/downloads.html this link.
Unzip the file
move unzipped folder to /usr/local/spark-2.4.5/ location
Set export SPARK_HOME=/usr/local/spark-2.4.5 as environment variable.
from any location fire pyspark as command.
This should launch jupyter notebook 


# in case when we are getting connection refused error while loading data from file to DataFrame.
https://stackoverflow.com/questions/31743586/apache-spark-running-locally-giving-refused-connection-error